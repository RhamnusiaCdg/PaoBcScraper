import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import base64
import os
import sys
from google.oauth2 import service_account
from googleapiclient.discovery import build
import logging
import re

# ==========================================================
# LOGGING SETUP
# ==========================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# ==========================================================
# ENVIRONMENT SETUP
# ==========================================================
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# ==========================================================
# Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£
# ==========================================================
CALENDAR_ID = os.environ.get("CALENDAR_ID", "primary")
SCOPES = ["https://www.googleapis.com/auth/calendar"]
BASE_URL = "https://www.paobc.gr/schedule/page/"
MAX_PAGES = 10
REQUEST_TIMEOUT = 15


def normalize_team_name(name):
    """
    Normalize team names for comparison
    Î‘Ï†Î±Î¹ÏÎµÎ¯ emojis, suffixes (BC, AKTOR), ÎºÎ±Î¹ ÎºÎ¬Î½ÎµÎ¹ uppercase
    """
    if not name:
        return ""
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ emojis
    name = re.sub(r'[^\w\s-]', '', str(name), flags=re.UNICODE)
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÎºÎ¿Î¹Î½ÏÎ½ suffixes
    suffixes = [" BC", " AKTOR", " ATHENS", " OPAP", " BC", " AKTOR"]
    for suffix in suffixes:
        name = name.replace(suffix, "")
    
    # Uppercase ÎºÎ±Î¹ trim
    name = name.strip().upper()
    
    # Î‘Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎºÎµÎ½ÏÎ½ Î¼Îµ Î­Î½Î±
    name = re.sub(r'\s+', ' ', name)
    
    return name


def authenticate_google_calendar():
    """
    Authenticate with Google Calendar using Service Account
    Î”ÎµÎ½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î ÎŸÎ¤Î• Î±Î½Î±Î½Î­Ï‰ÏƒÎ· token!
    """
    logger.info("ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï„Î±Ï…Ï„ÏŒÏ„Î·Ï„Î±Ï‚ Google Calendar (Service Account)...")
    
    try:
        # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ environment variable (GitHub Actions)
        if os.getenv('SERVICE_ACCOUNT_KEY'):
            logger.info("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· credentials Î±Ï€ÏŒ environment variable")
            service_account_info = json.loads(
                base64.b64decode(os.getenv('SERVICE_ACCOUNT_KEY'))
            )
            credentials = service_account.Credentials.from_service_account_info(
                service_account_info,
                scopes=SCOPES
            )
        
        # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ (local development)
        elif os.path.exists('service-account-key.json'):
            logger.info("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· credentials Î±Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿")
            credentials = service_account.Credentials.from_service_account_file(
                'service-account-key.json',
                scopes=SCOPES
            )
        
        else:
            raise FileNotFoundError(
                "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ service account credentials! "
                "Î’Î¬Î»Îµ Ï„Î¿ service-account-key.json ÏƒÏ„Î¿ directory Î® "
                "ÏŒÏÎ¹ÏƒÎµ Ï„Î¿ SERVICE_ACCOUNT_KEY environment variable"
            )
        
        service = build("calendar", "v3", credentials=credentials)
        logger.info("âœ“ Î•Ï€Î¹Ï„Ï…Ï‡Î®Ï‚ Ï„Î±Ï…Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Îµ Service Account")
        return service
        
    except FileNotFoundError as e:
        logger.error(f"âŒ {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Ï„Î±Ï…Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚: {e}")
        sys.exit(1)


def scrape_pao_schedule():
    """Scrape Panathinaikos BC schedule from all pages"""
    all_matches = []
    seen_matches = set()
    page = 1
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    consecutive_empty_pages = 0

    logger.info(f"ÎˆÎ½Î±ÏÎ¾Î· ÏƒÎ¬ÏÏ‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ {BASE_URL}")

    while page <= MAX_PAGES:
        if page == 1:
            url = "https://www.paobc.gr/schedule/"
        else:
            url = f"{BASE_URL}{page}/"

        logger.info(f"Î£Î¬ÏÏ‰ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚ {page}: {url}")

        try:
            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            matches = soup.find_all("div", class_="game")

            if not matches:
                consecutive_empty_pages += 1
                logger.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Î³ÏÎ½ÎµÏ‚ ÏƒÏ„Î· ÏƒÎµÎ»Î¯Î´Î± {page}")
                
                if consecutive_empty_pages >= 2:
                    logger.info(f"Î¤ÎµÏÎ¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚: {consecutive_empty_pages} ÏƒÏ…Î½ÎµÏ‡ÏŒÎ¼ÎµÎ½ÎµÏ‚ ÎºÎµÎ½Î­Ï‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚")
                    break
                
                page += 1
                continue
            
            consecutive_empty_pages = 0
            matches_on_page = 0

            for match in matches:
                try:
                    data_div = match.find("div", class_="game__data")
                    header_div = match.find("div", class_="game__header")

                    if not data_div or not header_div:
                        continue

                    competition = data_div.find("div", class_="game__data__league").text.strip()

                    date_div = data_div.find("div", class_="game__data__date")
                    date_spans = date_div.find_all("span")
                    date_text = date_spans[0].text.strip() if len(date_spans) > 0 else ""
                    time_text = date_spans[1].text.strip() if len(date_spans) > 1 else ""

                    venue_div = data_div.find("div", class_="game__data__stadium")
                    venue = venue_div.text.strip() if venue_div else "ÎŸÎ‘ÎšÎ‘"

                    name_div = header_div.find("div", class_="game__header__name")
                    team_spans = name_div.find_all("span")
                    home_team = team_spans[0].text.strip() if len(team_spans) > 0 else ""
                    away_team = team_spans[1].text.strip() if len(team_spans) > 1 else ""

                    match_id = f"{home_team}|{away_team}|{date_text}"

                    if match_id in seen_matches:
                        logger.debug(f"â­ï¸ Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿Ï…: {home_team} vs {away_team}")
                        continue

                    seen_matches.add(match_id)

                    match_data = {
                        "date": date_text,
                        "time": time_text,
                        "home_team": home_team,
                        "away_team": away_team,
                        "competition": competition,
                        "venue": venue,
                    }

                    all_matches.append(match_data)
                    matches_on_page += 1
                    logger.debug(f"Î’ÏÎ­Î¸Î·ÎºÎµ: {home_team} vs {away_team} ÏƒÏ„Î¹Ï‚ {date_text}")

                except AttributeError as e:
                    logger.warning(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î±Î³ÏÎ½Î±: {e}")
                    continue

            logger.info(f"âœ“ Î£ÎµÎ»Î¯Î´Î± {page}: {matches_on_page} Î±Î³ÏÎ½ÎµÏ‚")
            page += 1

        except requests.Timeout:
            logger.error(f"Timeout ÏƒÏ„Î· ÏƒÎµÎ»Î¯Î´Î± {page} - Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Ï„Î·Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î·...")
            page += 1
            continue
        except requests.RequestException as e:
            logger.error(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¹ÎºÏ„ÏÎ¿Ï… ÏƒÏ„Î· ÏƒÎµÎ»Î¯Î´Î± {page}: {e}")
            if all_matches:
                logger.warning(f"Î£Ï…Î½Î­Ï‡ÎµÎ¹Î± Î¼Îµ {len(all_matches)} Î±Î³ÏÎ½ÎµÏ‚ Ï€Î¿Ï… Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î¼Î­Ï‡ÏÎ¹ Ï„ÏÏÎ±")
                break
            else:
                logger.error("ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Î³ÏÎ½ÎµÏ‚")
                sys.exit(1)

    logger.info(f"ğŸ“Š Î£ÏÎ½Î¿Î»Î¿: {len(all_matches)} Î¼Î¿Î½Î±Î´Î¹ÎºÎ¿Î¯ Î±Î³ÏÎ½ÎµÏ‚ Î±Ï€ÏŒ {page-1} ÏƒÎµÎ»Î¯Î´ÎµÏ‚")
    return all_matches


def parse_match_datetime(date_text, time_text):
    """Parse date/time to datetime object"""
    try:
        greek_days = [
            "Î”ÎµÏ…Ï„Î­ÏÎ±", "Î¤ÏÎ¯Ï„Î·", "Î¤ÎµÏ„Î¬ÏÏ„Î·", "Î Î­Î¼Ï€Ï„Î·", 
            "Î Î±ÏÎ±ÏƒÎºÎµÏ…Î®", "Î£Î¬Î²Î²Î±Ï„Î¿", "ÎšÏ…ÏÎ¹Î±ÎºÎ®"
        ]

        for day in greek_days:
            date_text = date_text.replace(day + ",", "").replace(day, "")

        greek_months = {
            "Î™Î±Î½Î¿Ï…Î±ÏÎ¯Î¿Ï…": "January", "Î™Î±Î½": "January",
            "Î¦ÎµÎ²ÏÎ¿Ï…Î±ÏÎ¯Î¿Ï…": "February", "Î¦ÎµÎ²": "February",
            "ÎœÎ±ÏÏ„Î¯Î¿Ï…": "March", "ÎœÎ±Ï": "March",
            "Î‘Ï€ÏÎ¹Î»Î¯Î¿Ï…": "April", "Î‘Ï€Ï": "April",
            "ÎœÎ±ÎÎ¿Ï…": "May", "ÎœÎ¬Î¹": "May",
            "Î™Î¿Ï…Î½Î¯Î¿Ï…": "June", "Î™Î¿Ï…Î½": "June",
            "Î™Î¿Ï…Î»Î¯Î¿Ï…": "July", "Î™Î¿Ï…Î»": "July",
            "Î‘Ï…Î³Î¿ÏÏƒÏ„Î¿Ï…": "August", "Î‘Ï…Î³": "August",
            "Î£ÎµÏ€Ï„ÎµÎ¼Î²ÏÎ¯Î¿Ï…": "September", "Î£ÎµÏ€": "September",
            "ÎŸÎºÏ„Ï‰Î²ÏÎ¯Î¿Ï…": "October", "ÎŸÎºÏ„": "October",
            "ÎÎ¿ÎµÎ¼Î²ÏÎ¯Î¿Ï…": "November", "ÎÎ¿Îµ": "November",
            "Î”ÎµÎºÎµÎ¼Î²ÏÎ¯Î¿Ï…": "December", "Î”ÎµÎº": "December",
        }

        english_months = {
            "January": "01", "February": "02", "March": "03",
            "April": "04", "May": "05", "June": "06",
            "July": "07", "August": "08", "September": "09",
            "October": "10", "November": "11", "December": "12",
            "Jan": "01", "Feb": "02", "Mar": "03",
            "Apr": "04", "Jun": "06", "Jul": "07",
            "Aug": "08", "Sep": "09", "Oct": "10",
            "Nov": "11", "Dec": "12",
        }

        for greek, english in greek_months.items():
            date_text = date_text.replace(greek, english)

        english_days = [
            "Monday", "Tuesday", "Wednesday", "Thursday",
            "Friday", "Saturday", "Sunday"
        ]
        for day in english_days:
            date_text = date_text.replace(day + ",", "").replace(day, "")

        date_text = date_text.strip().replace(",", "")

        parts = date_text.split()
        if len(parts) >= 3:
            day = parts[0]
            month = parts[1]
            year = parts[2]

            month_num = english_months.get(month, month)

            time = time_text.strip()
            if not time or ":" not in time or len(time) > 5:
                time = "21:15"

            datetime_str = f"{day}/{month_num}/{year} {time}"
            match_datetime = datetime.strptime(datetime_str, "%d/%m/%Y %H:%M")

            return match_datetime

        return None

    except Exception as e:
        logger.warning(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚ '{date_text} {time_text}': {e}")
        return None


def create_match_identifier(match_data, match_datetime):
    """
    Create unique identifier for a match
    """
    home_normalized = normalize_team_name(match_data['home_team'])
    away_normalized = normalize_team_name(match_data['away_team'])
    
    # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î³Î¹Î± Î½Î± Î¼Î·Î½ Î­Ï‡ÎµÎ¹ ÏƒÎ·Î¼Î±ÏƒÎ¯Î± Î· ÏƒÎµÎ¹ÏÎ¬
    teams_sorted = sorted([home_normalized, away_normalized])
    
    if match_datetime:
        date_part = match_datetime.strftime("%Y-%m-%d")
        return f"{teams_sorted[0]}|{teams_sorted[1]}|{date_part}"
    
    return f"{teams_sorted[0]}|{teams_sorted[1]}"


def extract_teams_from_event(event):
    """Î•Î¾Î¬Î³ÎµÎ¹ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± Ï„Ï‰Î½ Î¿Î¼Î¬Î´Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿ event"""
    summary = event.get("summary", "")
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ emojis ÎºÎ±Î¹ Î¬Î»Î»Ï‰Î½ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÏ‰Î½
    clean_summary = re.sub(r'[^\w\s\-\[\]]', ' ', summary, flags=re.UNICODE)
    clean_summary = re.sub(r'\s+', ' ', clean_summary).strip()
    
    # Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± pattern "TeamA - TeamB"
    if " - " in clean_summary:
        # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Î¿Ï… [dd/mm] Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        if "[" in clean_summary:
            clean_summary = clean_summary.split("[")[0].strip()
        
        parts = clean_summary.split(" - ")
        if len(parts) >= 2:
            home_team = parts[0].strip()
            away_team = parts[1].strip()
            
            return home_team, away_team
    
    return None, None


def get_existing_events_map(calendar_events):
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î­Î½Î± map Î¼Îµ Ï„Î± Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î± events Î³Î¹Î± Î³ÏÎ®Î³Î¿ÏÎ· Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
    """
    events_map = {}
    
    for event in calendar_events:
        try:
            event_start = event.get("start", {}).get("dateTime", "")
            if not event_start:
                continue
                
            home_team, away_team = extract_teams_from_event(event)
            if not home_team or not away_team:
                continue
            
            # Normalize Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î±
            home_normalized = normalize_team_name(home_team)
            away_normalized = normalize_team_name(away_team)
            teams_sorted = sorted([home_normalized, away_normalized])
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± datetime
            event_datetime = datetime.fromisoformat(
                event_start.replace("Z", "+00:00")
            ).replace(tzinfo=None)
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± key Î³Î¹Î± Ï„Î¿ map
            date_key = event_datetime.strftime("%Y-%m-%d")
            event_key = f"{teams_sorted[0]}|{teams_sorted[1]}|{date_key}"
            
            events_map[event_key] = {
                "event": event,
                "datetime": event_datetime,
                "original_home": home_team,
                "original_away": away_team
            }
            
        except Exception as e:
            logger.warning(f"Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ event: {e}")
            continue
    
    logger.info(f"Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ events map Î¼Îµ {len(events_map)} entries")
    return events_map


def create_event_data(match_data, match_datetime):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Î­Î½Î± event"""
    date_str = match_datetime.strftime("%d/%m")
    summary = f"â˜˜ï¸ğŸ€ {match_data['home_team']} - {match_data['away_team']} [{date_str}]"
    end_datetime = match_datetime + timedelta(hours=2)
    
    return {
        "summary": summary,
        "location": match_data.get("venue", "ÎŸÎ‘ÎšÎ‘"),
        "description": f"Î”Î¹Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ·: {match_data.get('competition', 'Î•Î»Î»Î·Î½Î¹ÎºÏŒ Î ÏÏ‰Ï„Î¬Î¸Î»Î·Î¼Î±')}",
        "start": {
            "dateTime": match_datetime.isoformat(),
            "timeZone": "Europe/Athens",
        },
        "end": {
            "dateTime": end_datetime.isoformat(),
            "timeZone": "Europe/Athens",
        },
        "reminders": {
            "useDefault": False,
            "overrides": [
                {"method": "popup", "minutes": 60},
            ],
        },
    }


def sync_match_with_calendar(service, match_data, existing_events_map):
    """
    Î£Ï…Î³Ï‡ÏÎ¿Î½Î¯Î¶ÎµÎ¹ Î­Î½Î±Î½ Î±Î³ÏÎ½Î± Î¼Îµ Ï„Î¿ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿:
    1. Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¼Îµ Î¯Î´Î¹ÎµÏ‚ ÏÏÎµÏ‚: Î´ÎµÎ½ ÎºÎ¬Î½ÎµÎ¹ Ï„Î¯Ï€Î¿Ï„Î±
    2. Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏÏÎµÏ‚: ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÎ¹
    3. Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Î½Î­Î¿
    """
    try:
        match_datetime = parse_match_datetime(match_data["date"], match_data["time"])
        if not match_datetime:
            logger.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î±Î³ÏÎ½Î± Î»ÏŒÎ³Ï‰ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î¿Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚: {match_data['home_team']} vs {match_data['away_team']}")
            return False, None

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± key Î³Î¹Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
        home_normalized = normalize_team_name(match_data['home_team'])
        away_normalized = normalize_team_name(match_data['away_team'])
        teams_sorted = sorted([home_normalized, away_normalized])
        date_key = match_datetime.strftime("%Y-%m-%d")
        match_key = f"{teams_sorted[0]}|{teams_sorted[1]}|{date_key}"
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± event data
        event_data = create_event_data(match_data, match_datetime)
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î·
        if match_key in existing_events_map:
            existing_info = existing_events_map[match_key]
            existing_event = existing_info["event"]
            existing_datetime = existing_info["datetime"]
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Î­Ï‡Î¿Ï…Î½ Î±Î»Î»Î¬Î¾ÎµÎ¹ Î¿Î¹ ÏÏÎµÏ‚
            time_diff = abs((existing_datetime - match_datetime).total_seconds())
            
            if time_diff < 60:  # ÎœÎ¹ÎºÏÏŒÏ„ÎµÏÎ¿ Î±Ï€ÏŒ 1 Î»ÎµÏ€Ï„ÏŒ Î´Î¹Î±Ï†Î¿ÏÎ¬
                logger.debug(f"â„¹ï¸ Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· Î¼Îµ Î¯Î´Î¹ÎµÏ‚ ÏÏÎµÏ‚: {match_data['home_team']} vs {match_data['away_team']} "
                           f"({match_datetime.strftime('%H:%M')})")
                return True, match_key
            else:
                # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· ÏÏÎ±Ï‚
                existing_time_str = existing_datetime.strftime("%H:%M")
                new_time_str = match_datetime.strftime("%H:%M")
                
                service.events().update(
                    calendarId=CALENDAR_ID, 
                    eventId=existing_event["id"], 
                    body=event_data
                ).execute()
                
                logger.info(f"ğŸ”„ Î•ÎÎ—ÎœÎ•Î¡Î©Î£Î— Î©Î¡Î‘Î£: {match_data['home_team']} vs {match_data['away_team']} "
                          f"({existing_time_str} â†’ {new_time_str})")
                return True, match_key
        else:
            # ÎÎ­Î¿Ï‚ Î±Î³ÏÎ½Î±Ï‚ - Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ·
            service.events().insert(
                calendarId=CALENDAR_ID, 
                body=event_data
            ).execute()
            
            logger.info(f"âœ… Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—: {match_data['home_team']} vs {match_data['away_team']} "
                      f"({match_datetime.strftime('%d/%m/%Y %H:%M')})")
            return True, match_key
            
    except Exception as e:
        logger.error(f"Î£Ï†Î¬Î»Î¼Î± ÏƒÏ…Î³Ï‡ÏÎ¿Î½Î¹ÏƒÎ¼Î¿Ï Î±Î³ÏÎ½Î±: {e}")
        return False, None


def get_all_pao_events(service):
    """Get all PAO basketball events from calendar"""
    try:
        time_min = (datetime.now() - timedelta(days=180)).isoformat() + "Z"
        time_max = (datetime.now() + timedelta(days=540)).isoformat() + "Z"

        logger.info(
            f"Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· events Î±Ï€ÏŒ {(datetime.now() - timedelta(days=180)).strftime('%d/%m/%Y')} "
            f"Î­Ï‰Ï‚ {(datetime.now() + timedelta(days=540)).strftime('%d/%m/%Y')}"
        )

        events_result = (
            service.events()
            .list(
                calendarId=CALENDAR_ID,
                timeMin=time_min,
                timeMax=time_max,
                maxResults=2500,
                singleEvents=True,
                orderBy="startTime",
            )
            .execute()
        )

        all_events = events_result.get("items", [])

        pao_events = []
        for event in all_events:
            summary = event.get("summary", "")
            if (
                "ğŸ€" in summary
                or "â˜˜ï¸" in summary
                or "Î Î‘ÎŸ" in summary.upper()
                or "PANATHINAIKOS" in summary.upper()
                or (" - " in summary and any(x in summary.upper() for x in ["VS", "VS.", "Î‘Î“Î©ÎÎ‘Î£", "Î‘Î“Î©ÎÎ‘"]))
            ):
                pao_events.append(event)

        logger.info(f"âœ“ Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(pao_events)} PAO basketball events ÏƒÏ„Î¿ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿")
        return pao_events

    except Exception as e:
        logger.error(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ events Î±Ï€ÏŒ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿: {e}")
        return []


def delete_obsolete_events(service, website_match_keys, existing_events_map):
    """
    Î”Î¹Î±Î³ÏÎ¬Ï†ÎµÎ¹ events Ï€Î¿Ï… Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÏ„Î¿ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿ Î¼Î±Ï‚ Î±Î»Î»Î¬ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÏ„Î¿ website
    """
    deleted_count = 0
    
    logger.info(f"ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ {len(existing_events_map)} events Î³Î¹Î± Ï€Î¹Î¸Î±Î½Î® Î´Î¹Î±Î³ÏÎ±Ï†Î®...")
    logger.info(f"ÎˆÎ³ÎºÏ…ÏÎ± keys Î±Ï€ÏŒ website: {len(website_match_keys)}")
    
    for event_key, event_info in list(existing_events_map.items()):
        if event_key not in website_match_keys:
            try:
                event = event_info["event"]
                event_datetime = event_info["datetime"]
                home_team = event_info.get("original_home", "Unknown")
                away_team = event_info.get("original_away", "Unknown")
                
                # Î”Î¹Î±Î³ÏÎ±Ï†Î® event
                service.events().delete(
                    calendarId=CALENDAR_ID, 
                    eventId=event["id"]
                ).execute()
                
                logger.info(f"ğŸ—‘ï¸ Î”Î™Î‘Î“Î¡Î‘Î¦Î—: {home_team} vs {away_team} "
                          f"({event_datetime.strftime('%d/%m/%Y %H:%M')})")
                deleted_count += 1
                
                # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ map
                del existing_events_map[event_key]
                
            except Exception as e:
                logger.warning(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¹Î±Î³ÏÎ±Ï†Î®Ï‚ event {event_key}: {e}")
                continue
    
    return deleted_count


def main():
    """Main function with improved sync logic"""
    logger.info("=" * 70)
    logger.info("ğŸ€ Panathinaikos BC Schedule Scraper - ÎˆÎ½Î±ÏÎ¾Î·")
    logger.info("=" * 70)

    # Authenticate Google Calendar with Service Account
    service = authenticate_google_calendar()

    # PHASE 0: Get existing calendar events
    logger.info("\nğŸ“… Î¦Î‘Î£Î— 0: Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ· Ï…Ï€Î±ÏÏ‡ÏŒÎ½Ï„Ï‰Î½ events...")
    logger.info("-" * 70)
    existing_calendar_events = get_all_pao_events(service)
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± map Î³Î¹Î± Î³ÏÎ®Î³Î¿ÏÎ· Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
    existing_events_map = get_existing_events_map(existing_calendar_events)

    # PHASE 1: Scrape schedule from website
    logger.info(f"\nğŸŒ Î¦Î‘Î£Î— 1: Î£Î¬ÏÏ‰ÏƒÎ· Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï€ÏŒ paobc.gr...")
    logger.info("-" * 70)
    website_matches = scrape_pao_schedule()

    if not website_matches:
        logger.error("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Î³ÏÎ½ÎµÏ‚ - Ï„ÎµÏÎ¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚")
        sys.exit(1)

    # PHASE 2: Sync matches from website to calendar
    logger.info(f"\nğŸ”„ Î¦Î‘Î£Î— 2: Î£Ï…Î³Ï‡ÏÎ¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ {len(website_matches)} Î±Î³ÏÎ½Ï‰Î½ Î¼Îµ Ï„Î¿ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿...")
    logger.info("-" * 70)

    synced_count = 0
    website_match_keys = set()
    
    for match in website_matches:
        synced, match_key = sync_match_with_calendar(service, match, existing_events_map)
        if synced and match_key:
            synced_count += 1
            website_match_keys.add(match_key)
    
    logger.info(f"Î£Ï…Î³Ï‡ÏÎ¿Î½Î¯ÏƒÏ„Î·ÎºÎ±Î½ {synced_count} Î±Ï€ÏŒ {len(website_matches)} Î±Î³ÏÎ½ÎµÏ‚")
    logger.info(f"ÎœÎ¿Î½Î±Î´Î¹ÎºÎ¬ keys Î±Ï€ÏŒ website: {len(website_match_keys)}")

    # PHASE 3: Delete events that no longer exist on website
    logger.info(f"\nğŸ—‘ï¸ Î¦Î‘Î£Î— 3: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î±Î³ÏÎ½ÎµÏ‚ Ï€ÏÎ¿Ï‚ Î´Î¹Î±Î³ÏÎ±Ï†Î®...")
    logger.info("-" * 70)

    deleted_count = delete_obsolete_events(service, website_match_keys, existing_events_map)

    # Summary
    logger.info("\n" + "=" * 70)
    logger.info("âœ… ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ• Î•Î Î™Î¤Î¥Î§Î©Î£!")
    logger.info(f"   â€¢ Î‘Î³ÏÎ½ÎµÏ‚ ÏƒÏ„Î¿ site: {len(website_matches)}")
    logger.info(f"   â€¢ Î£Ï…Î³Ï‡ÏÎ¿Î½Î¯ÏƒÏ„Î·ÎºÎ±Î½: {synced_count}")
    logger.info(f"   â€¢ Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎ±Î½: {deleted_count}")
    logger.info(f"   â€¢ Î¥Ï€ÏŒÎ»Î¿Î¹Ï€Î± events ÏƒÏ„Î¿ Î·Î¼ÎµÏÎ¿Î»ÏŒÎ³Î¹Î¿: {len(existing_events_map)}")
    logger.info("=" * 70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ Î”Î¹Î±ÎºÏŒÏ€Î·ÎºÎµ Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î·")
        sys.exit(0)
    except Exception as e:
        logger.error(f"\nâŒ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î±: {e}", exc_info=True)
        sys.exit(1)